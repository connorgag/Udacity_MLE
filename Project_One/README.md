# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
later
**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was a Voting Ensemble created by AutoML. 
However, while the accuracy for AutoML was higher than the Hyperdrive model, it was not very significant (< 1% difference). 


## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
This pipeline takes in the data, cleans it using train.py, then uses Hyperdrive to tune the parameters. 
The classification algorithm that it uses is Logistic Regression. 

It uses Random Parameter Sampling and the Bandit Early Stopping Policy. 

**What are the benefits of the parameter sampler you chose?**
The benefit of using random parameter sampling is that it is significantly faster than grid sampling, yet it doesn't significantly decrease the accuracy. This works well for projects like this, when it isn't necessary to exhaust unnecessary resources. 

**What are the benefits of the early stopping policy you chose?**
The benefit of using the Bandit policy is that it focuses on having one model that maximizes the primary metrics. Bandit stops any jobs that are a certain amount below the threshold set by the current best model. 


## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
AutoML used Voting Ensemble, which combines the result of multiple algorithms; here are a few of the algorithms used in it: LightGBM, XGBoostClassifier, and SGD. 
For LightGBM, some of the hyperparameters that it tuned were learning rate (~ 0.0578) and num_leaves (137). 


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
Hyperdrive had an accuracy of 0.9109007. 
AutoML had an accuracy of 0.91800. 

I expected AutoML to be significantly better because it tests multiple kinds of algorithms, but this was not the case. VotingEnsemble using a balanced approach by combining the output of multiple models, so this could account for the slightly higher accuracy. Hyperdrive only used Logistic Regression and didn't try out any other models, so AutoML has the upperhand when it comes to testing out a variety of multiple algorithms as well as hyperparameters. 

However, in any case, the difference is negligable. 

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
later
